{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "文本二分类问题.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvG8rec/0vfwe4qFvGhCKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hou-jing/-repository-experiment/blob/main/%E6%96%87%E6%9C%AC%E4%BA%8C%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppCiN6wWaUGi",
        "outputId": "58609611-a049-41a8-a83a-37de6f4411cf"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path='/content/drive/My Drive/test.txt'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ybe9G5vbMx8"
      },
      "source": [
        "import pandas as pd\n",
        "def file_process(file_path):\n",
        "    with open(file_path,'r',encoding='utf_8') as f:\n",
        "        labels=[]\n",
        "        texts=[]\n",
        "        for line in f:\n",
        "            line=line.split(' ')\n",
        "            labels.append(line[0])\n",
        "            texts.append(line[1])     \n",
        "    return labels,texts\n",
        "def describe_file(file_path):\n",
        "    labels,texts=file_process(file_path)\n",
        "    file_df=pd.DataFrame({'label':labels,'text':texts})\n",
        "    file_length=file_df['text'].apply(lambda x:len(x))\n",
        "    return file_df\n",
        "test_df=describe_file(path)\n",
        "print(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soIfDcsLceYJ"
      },
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsecSfI4dEz1",
        "outputId": "16aa2078-974f-4cad-fb8b-3309e9d5b987"
      },
      "source": [
        "test_text=[text for text in test_df['text']]\n",
        "print(type(test_text))\n",
        "encoded_input = tokenizer(test_text,padding=True ,return_tensors='tf')#tokenizer 处理（list(str）或者str type)\n",
        "output = model(encoded_input)\n",
        "print(output.keys())\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "odict_keys(['last_hidden_state', 'pooler_output'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LihE5ImfKkk",
        "outputId": "f778b456-9b71-450b-ded2-ccbd0165afb4"
      },
      "source": [
        "import tensorflow as tf\n",
        "y_test=[int(label) for label in test_df['label']]\n",
        "y_train=output['pooler_output']\n",
        "y_test=tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "# y_test=torch.FloatTensor(y_test)\n",
        "print(output['pooler_output'].shape,len(y_test))\n",
        "print(type(y_test),type(y_train))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 768) 50\n",
            "<class 'tensorflow.python.framework.ops.EagerTensor'> <class 'tensorflow.python.framework.ops.EagerTensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuqTmuhSgnoN",
        "outputId": "a1929b6f-6992-4a26-dc3f-f2260e0fc733"
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import LSTM, Dense, Embedding, Dropout,Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def build_classifier_model():\n",
        "  x_input=Input(shape=(768,))\n",
        "  x_out=Dense(4,activation='relu')(x_input)\n",
        "  x_out=Dense(1,activation='softmax')(x_out)\n",
        "  return Model(x_input,x_out)\n",
        "classifier_model=build_classifier_model()\n",
        "print(classifier_model.summary())\n",
        "classifier_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "classifier_model.fit(y_train,y_test,epochs=2)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 768)]             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 4)                 3076      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,081\n",
            "Trainable params: 3,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "2/2 [==============================] - 1s 8ms/step - loss: 0.0000e+00 - accuracy: 0.4800\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 0.4800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4045d48190>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}